{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ff4120-f9ba-4941-9600-19c9f25671bc",
   "metadata": {},
   "source": [
    "**Title**: Text Analytics 3.2 Exercises  \n",
    "**Author**: Ryan Weeks  \n",
    "**Date**: 3/26/2025  \n",
    "**Description**: In this exercise, I used Python to extract and process text from PDFs and an image. I worked with PyPDF and tabula-py to read text and tables from two different PDF files, then used pytesseract to perform OCR on an image containing printed text. Finally, I used spaCy to tokenize the extracted image text and analyze each token’s part of speech and dependency.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c92b212-073d-4aa9-bff1-88f5d83cda57",
   "metadata": {},
   "source": [
    "### Exercise 1: Reading Text from a PDF without Tables (Using PyPDF)\r\n",
    "\r\n",
    "In this step, I’m using the `pypdf` library to extract text from a PDF that contains only plain text. `pypdf` is lightweight and straightforward for basic text extraction, although it doesn't support layout or table parsing.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b20116-8b96-460c-8fc6-fa80efd2fbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercises \n",
      "1. Create a simple PDF file without tables (you can use Microsoft Word to create a document and \n",
      "save it as a PDF file) and read the text using Python. Print the results.  \n",
      "2. Create a simple PDF file with tables (you can use Microsoft Word to create a document and save \n",
      "it as a PDF file) and read the text using Python. Print the results. \n",
      "3. Go through the Microsoft tutorial to create a form processing model using the Microsoft invoice \n",
      "samples. Do a “quick test” using the test invoice. Then, after reading about how you can \n",
      "incorporate your model in Power Automate, create a simple Power Automate flow that reads \n",
      "that test invoice and shows the data fields within it. (There may be a tutorial available from \n",
      "Microsoft that shows you how to do this.)  \n",
      "4. Assuming you installed Tesseract, use pytesseract to read the Bowers text image found in the \n",
      "GitHub for Week 3 (week_3\\data\\bowers.jpg). Then use spaCy to print out the tokens (the text, \n",
      "part of speech, and dependency).  \n",
      "For the Python assignments, you can submit Jupyter Notebooks or PDFs of your code (one for each \n",
      "exercise). If you submit .py files you need to also include a PDF or attachment of your results. \n",
      "For the Power Automate assignment, share your completed flow with me (fneugebauer@bellevue.edu).  \n",
      "Don’t forget to work on your project – Milestone 2 is due next week. \n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "# File path to the PDF with no tables\n",
    "pdf_path_no_tables = \"C:/Users/Weekseey/Documents/Bellevue Work/Text Analytics/Week_3_No_Tables.pdf\"\n",
    "\n",
    "# Create a PDF reader object\n",
    "reader = PdfReader(pdf_path_no_tables)\n",
    "\n",
    "# Extract text from all pages\n",
    "all_text_no_tables = \"\"\n",
    "for page in reader.pages:\n",
    "    all_text_no_tables += page.extract_text()\n",
    "\n",
    "print(all_text_no_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f257c8-90db-474c-aea7-0603e8da9ac6",
   "metadata": {},
   "source": [
    "The PDF text was extracted successfully using `pypdf`. Since this file only had regular text, the results are clean and readable. For documents with more complex layouts or visual elements, `pypdf` might miss some structure.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71339b0-4aa7-4caf-aace-607196cffbe8",
   "metadata": {},
   "source": [
    "### Exercise 2: Reading Text from a PDF with Tables (Using tabula-py)\r\n",
    "W while libraries like `pypdf` and `PyMuPDF` are great for extracting plain text, they don't preserve the structure of tables very well. That's where `tabula-py` comes in — it's specifically designed to extract tabular data from PDFs into a structured format like a DataFrame.\r\n",
    "\r\n",
    "Since this PDF includes a table, I’ll use `tabula-py` to pull the data in a more organized way.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "674c9496-9bc7-4c43-83c3-291d8a28554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tables extracted: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.360550</td>\n",
       "      <td>Jun</td>\n",
       "      <td>-11.072800</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328324</td>\n",
       "      <td>July</td>\n",
       "      <td>4.601376</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.824882</td>\n",
       "      <td>Aug</td>\n",
       "      <td>17.351750</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.201020</td>\n",
       "      <td>Aug</td>\n",
       "      <td>6.084073</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1    X2         X3    X4\n",
       "0  14.360550   Jun -11.072800  asia\n",
       "1   0.328324  July   4.601376  asia\n",
       "2   3.824882   Aug  17.351750  asia\n",
       "3  -6.201020   Aug   6.084073  asia"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "\n",
    "# File path to the PDF with tables\n",
    "pdf_path_with_tables = \"C:/Users/Weekseey/Documents/Bellevue Work/Text Analytics/Week_3_With_Tables.pdf\"\n",
    "\n",
    "# Extract tables — returns a list of DataFrames\n",
    "tables = tabula.read_pdf(pdf_path_with_tables, pages='all', multiple_tables=True)\n",
    "\n",
    "# Show number of tables found and preview the first one\n",
    "print(f\"Number of tables extracted: {len(tables)}\")\n",
    "tables[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e9412-013b-4311-884c-b817e34668ad",
   "metadata": {},
   "source": [
    "`tabula-py` was able to extract the table from the PDF and return it as pandas a DataFrame. The table looks well-structured, and I can now work with the data using standard pandas operations.\r\n",
    "\r\n",
    "This worked much better than just pulling raw text — especially for PDFs that were meant to be read like spreadsheets.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914f7e3-468c-4c7b-8fd3-969cca46ade2",
   "metadata": {},
   "source": [
    "### Exercise 3: OCR and NLP with pytesseract and spaCy\r\n",
    "\r\n",
    "In this step, I'm using `pytesseract` to perform OCR (Optical Character Recognition) on a text image. The image contains a paragraph of printed text, and my goal is to extract that text, clean up any extraneous characters introduced during OCR, and then use `spaCy` to tokenize the text and identify parts of speech and dependencies.\r\n",
    "\r\n",
    "I'll start by downloading and loading the image, then extracting text with `pytesseract`, and finally processing it with `spaCy`.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9517ca42-9d1d-49fa-85c9-98bb01b1cc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Life and Work of\n",
      "Fredson Bowers\n",
      "\n",
      "by\n",
      "G. THOMAS TANSELLE\n",
      "\n",
      "N EVERY FIELD OF ENDEAVOR THERE ARE A FEW FIGURES WHOSE AGCOM-\n",
      "plishment and influence cause them to be the symbols of their age;\n",
      "their careers and oeuvres become the touchstones by which the\n",
      "field is measured and its history told. In the related pursuits of\n",
      "\n",
      "analytical and descriptive bibliography, textual criticism, and scholarly\n",
      "editing, Fredson Bowers was such a figure, dominating the four decades\n",
      "after 1949, when his Principles of Bibliographical Description was pub-\n",
      "lished. By 1973 the period was already being called “the age of Bowers”:\n",
      "in that year Norman Sanders, writing the chapter on textual scholarship\n",
      "for Stanley Wells's Shakespeare: Select Bibliographies, gave this title to\n",
      "a section of his essay. For most people, it would be achievement enough\n",
      "to rise to such a position in a field as complex as Shakespearean textual\n",
      "studies; but Bowers played an equally important role in other areas.\n",
      "Editors of nineteenth-century American authors, for example, would\n",
      "also have to call the recent past “the age of Bowers,” as would the writers\n",
      "of descriptive bibliographies of authors and presses. His ubiquity in\n",
      "the broad field of bibliographical and textual study, his seemingly com-\n",
      "plete possession of it, distinguished him from his illustrious predeces-\n",
      "sors and made him the personification of bibliographical scholarship in\n",
      "his time.\n",
      "\n",
      "When in 1969 Bowers was awarded the Gold Medal of the Biblio-\n",
      "graphical Society in London, John Carter’s citation referred to the\n",
      "Principles as “majestic,” called Bowers's current projects “formidable,”\n",
      "said that he had “imposed critical discipline” on the texts of several\n",
      "authors, described Studies in Bibliography as a “great and continuing\n",
      "achievement,” and included among his characteristics ‘uncompromising\n",
      "seriousness of purpose” and “professional intensity.” Bowers was not\n",
      "unaccustomed to such encomia, but he had also experienced his share of\n",
      "attacks: his scholarly positions were not universally popular, and he\n",
      "expressed them with an aggressiveness that almost seemed calculated to\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Tell pytesseract where to find the tesseract.exe\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Load image from the URL\n",
    "img_url = \"https://raw.githubusercontent.com/bellevue-university/dsc360/main/12%20Week/week_3/bowers.jpg\"\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Extract text from the image\n",
    "raw_text = pytesseract.image_to_string(img)\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b1fc21-eb8c-45ca-882d-37b1c29d9b0b",
   "metadata": {},
   "source": [
    "The raw OCR text from the image contains some extra characters like newline symbols (`\\n`), odd punctuation, and possibly words split across lines. I’ll now clean up the text by removing these extra characters to make it easier to process with `spaCy`.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3da2a58-c083-4f81-908e-a76df96f3e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Life and Work of Fredson Bowers  by G. THOMAS TANSELLE  N EVERY FIELD OF ENDEAVOR THERE ARE A FEW FIGURES WHOSE AGCOM- plishment and influence cause them to be the symbols of their age; their careers and oeuvres become the touchstones by which the field is measured and its history told. In the related pursuits of  analytical and descriptive bibliography, textual criticism, and scholarly editing, Fredson Bowers was such a figure, dominating the four decades after 1949, when his Principles of Bibliographical Description was pub- lished. By 1973 the period was already being called “the age of Bowers”: in that year Norman Sanders, writing the chapter on textual scholarship for Stanley Wells's Shakespeare: Select Bibliographies, gave this title to a section of his essay. For most people, it would be achievement enough to rise to such a position in a field as complex as Shakespearean textual studies; but Bowers played an equally important role in other areas. Editors of nineteenth-century American authors, for example, would also have to call the recent past “the age of Bowers,” as would the writers of descriptive bibliographies of authors and presses. His ubiquity in the broad field of bibliographical and textual study, his seemingly com- plete possession of it, distinguished him from his illustrious predeces- sors and made him the personification of bibliographical scholarship in his time.  When in 1969 Bowers was awarded the Gold Medal of the Biblio- graphical Society in London, John Carter’s citation referred to the Principles as “majestic,” called Bowers's current projects “formidable,” said that he had “imposed critical discipline” on the texts of several authors, described Studies in Bibliography as a “great and continuing achievement,” and included among his characteristics ‘uncompromising seriousness of purpose” and “professional intensity.” Bowers was not unaccustomed to such encomia, but he had also experienced his share of attacks: his scholarly positions were not universally popular, and he expressed them with an aggressiveness that almost seemed calculated to\n"
     ]
    }
   ],
   "source": [
    "# Basic cleanup: remove newlines and fix extra whitespace\n",
    "clean_text = raw_text.replace('\\n', ' ').strip()\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ab47f-ca2d-43f7-a51d-c629e5f5f3a6",
   "metadata": {},
   "source": [
    "The cleaned text looks much better — it reads like a proper paragraph now. This should be ready for spaCy to tokenize and analyze.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95fdc017-e658-407e-903a-4af4878b192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The             POS: DET        DEP: det\n",
      "Life            POS: PROPN      DEP: nsubj\n",
      "and             POS: CCONJ      DEP: cc\n",
      "Work            POS: NOUN       DEP: conj\n",
      "of              POS: ADP        DEP: prep\n",
      "Fredson         POS: PROPN      DEP: compound\n",
      "Bowers          POS: PROPN      DEP: pobj\n",
      "                POS: SPACE      DEP: dep\n",
      "by              POS: ADP        DEP: prep\n",
      "G.              POS: PROPN      DEP: compound\n",
      "THOMAS          POS: PROPN      DEP: compound\n",
      "TANSELLE        POS: PROPN      DEP: pobj\n",
      "                POS: SPACE      DEP: dep\n",
      "N               POS: PROPN      DEP: cc\n",
      "EVERY           POS: PROPN      DEP: compound\n",
      "FIELD           POS: NOUN       DEP: conj\n",
      "OF              POS: ADP        DEP: prep\n",
      "ENDEAVOR        POS: PROPN      DEP: pobj\n",
      "THERE           POS: PRON       DEP: appos\n",
      "ARE             POS: AUX        DEP: ccomp\n",
      "A               POS: DET        DEP: det\n",
      "FEW             POS: ADJ        DEP: amod\n",
      "FIGURES         POS: NOUN       DEP: npadvmod\n",
      "WHOSE           POS: PROPN      DEP: compound\n",
      "AGCOM-          POS: PROPN      DEP: compound\n",
      "plishment       POS: PROPN      DEP: nsubj\n",
      "and             POS: CCONJ      DEP: cc\n",
      "influence       POS: NOUN       DEP: conj\n",
      "cause           POS: VERB       DEP: ccomp\n",
      "them            POS: PRON       DEP: nsubj\n",
      "to              POS: PART       DEP: aux\n",
      "be              POS: AUX        DEP: ccomp\n",
      "the             POS: DET        DEP: det\n",
      "symbols         POS: NOUN       DEP: attr\n",
      "of              POS: ADP        DEP: prep\n",
      "their           POS: PRON       DEP: poss\n",
      "age             POS: NOUN       DEP: pobj\n",
      ";               POS: PUNCT      DEP: punct\n",
      "their           POS: PRON       DEP: poss\n",
      "careers         POS: NOUN       DEP: nsubj\n",
      "and             POS: CCONJ      DEP: cc\n",
      "oeuvres         POS: NOUN       DEP: conj\n",
      "become          POS: VERB       DEP: ROOT\n",
      "the             POS: DET        DEP: det\n",
      "touchstones     POS: NOUN       DEP: attr\n",
      "by              POS: ADP        DEP: prep\n",
      "which           POS: PRON       DEP: pobj\n",
      "the             POS: DET        DEP: det\n",
      "field           POS: NOUN       DEP: nsubjpass\n",
      "is              POS: AUX        DEP: auxpass\n",
      "measured        POS: VERB       DEP: relcl\n",
      "and             POS: CCONJ      DEP: cc\n",
      "its             POS: PRON       DEP: poss\n",
      "history         POS: NOUN       DEP: nsubj\n",
      "told            POS: VERB       DEP: conj\n",
      ".               POS: PUNCT      DEP: punct\n",
      "In              POS: ADP        DEP: prep\n",
      "the             POS: DET        DEP: det\n",
      "related         POS: ADJ        DEP: amod\n",
      "pursuits        POS: NOUN       DEP: pobj\n",
      "of              POS: ADP        DEP: prep\n",
      "                POS: SPACE      DEP: dep\n",
      "analytical      POS: ADJ        DEP: amod\n",
      "and             POS: CCONJ      DEP: cc\n",
      "descriptive     POS: ADJ        DEP: conj\n",
      "bibliography    POS: NOUN       DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "textual         POS: ADJ        DEP: amod\n",
      "criticism       POS: NOUN       DEP: conj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "and             POS: CCONJ      DEP: cc\n",
      "scholarly       POS: ADJ        DEP: amod\n",
      "editing         POS: NOUN       DEP: conj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "Fredson         POS: PROPN      DEP: compound\n",
      "Bowers          POS: PROPN      DEP: nsubj\n",
      "was             POS: AUX        DEP: ROOT\n",
      "such            POS: DET        DEP: predet\n",
      "a               POS: DET        DEP: det\n",
      "figure          POS: NOUN       DEP: attr\n",
      ",               POS: PUNCT      DEP: punct\n",
      "dominating      POS: VERB       DEP: advcl\n",
      "the             POS: DET        DEP: det\n",
      "four            POS: NUM        DEP: nummod\n",
      "decades         POS: NOUN       DEP: nsubjpass\n",
      "after           POS: ADP        DEP: prep\n",
      "1949            POS: NUM        DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "when            POS: SCONJ      DEP: advmod\n",
      "his             POS: PRON       DEP: poss\n",
      "Principles      POS: NOUN       DEP: nsubj\n",
      "of              POS: ADP        DEP: prep\n",
      "Bibliographical POS: PROPN      DEP: compound\n",
      "Description     POS: PROPN      DEP: pobj\n",
      "was             POS: AUX        DEP: auxpass\n",
      "pub-            POS: ADJ        DEP: advmod\n",
      "lished          POS: VERB       DEP: ccomp\n",
      ".               POS: PUNCT      DEP: punct\n",
      "By              POS: ADP        DEP: prep\n",
      "1973            POS: NUM        DEP: pobj\n",
      "the             POS: DET        DEP: det\n",
      "period          POS: NOUN       DEP: nsubjpass\n",
      "was             POS: AUX        DEP: aux\n",
      "already         POS: ADV        DEP: advmod\n",
      "being           POS: AUX        DEP: auxpass\n",
      "called          POS: VERB       DEP: ROOT\n",
      "“               POS: PUNCT      DEP: punct\n",
      "the             POS: DET        DEP: det\n",
      "age             POS: NOUN       DEP: oprd\n",
      "of              POS: ADP        DEP: prep\n",
      "Bowers          POS: PROPN      DEP: pobj\n",
      "”               POS: PUNCT      DEP: punct\n",
      ":               POS: PUNCT      DEP: punct\n",
      "in              POS: ADP        DEP: prep\n",
      "that            POS: DET        DEP: det\n",
      "year            POS: NOUN       DEP: pobj\n",
      "Norman          POS: PROPN      DEP: compound\n",
      "Sanders         POS: PROPN      DEP: oprd\n",
      ",               POS: PUNCT      DEP: punct\n",
      "writing         POS: VERB       DEP: advcl\n",
      "the             POS: DET        DEP: det\n",
      "chapter         POS: NOUN       DEP: dobj\n",
      "on              POS: ADP        DEP: prep\n",
      "textual         POS: ADJ        DEP: amod\n",
      "scholarship     POS: NOUN       DEP: pobj\n",
      "for             POS: ADP        DEP: prep\n",
      "Stanley         POS: PROPN      DEP: compound\n",
      "Wells           POS: PROPN      DEP: poss\n",
      "'s              POS: PART       DEP: case\n",
      "Shakespeare     POS: PROPN      DEP: pobj\n",
      ":               POS: PUNCT      DEP: punct\n",
      "Select          POS: PROPN      DEP: compound\n",
      "Bibliographies  POS: PROPN      DEP: appos\n",
      ",               POS: PUNCT      DEP: punct\n",
      "gave            POS: VERB       DEP: conj\n",
      "this            POS: DET        DEP: det\n",
      "title           POS: NOUN       DEP: dobj\n",
      "to              POS: ADP        DEP: prep\n",
      "a               POS: DET        DEP: det\n",
      "section         POS: NOUN       DEP: pobj\n",
      "of              POS: ADP        DEP: prep\n",
      "his             POS: PRON       DEP: poss\n",
      "essay           POS: NOUN       DEP: pobj\n",
      ".               POS: PUNCT      DEP: punct\n",
      "For             POS: ADP        DEP: prep\n",
      "most            POS: ADJ        DEP: amod\n",
      "people          POS: NOUN       DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "it              POS: PRON       DEP: nsubj\n",
      "would           POS: AUX        DEP: aux\n",
      "be              POS: AUX        DEP: ROOT\n",
      "achievement     POS: NOUN       DEP: attr\n",
      "enough          POS: ADV        DEP: advmod\n",
      "to              POS: PART       DEP: aux\n",
      "rise            POS: VERB       DEP: xcomp\n",
      "to              POS: ADP        DEP: prep\n",
      "such            POS: DET        DEP: predet\n",
      "a               POS: DET        DEP: det\n",
      "position        POS: NOUN       DEP: pobj\n",
      "in              POS: ADP        DEP: prep\n",
      "a               POS: DET        DEP: det\n",
      "field           POS: NOUN       DEP: pobj\n",
      "as              POS: ADV        DEP: advmod\n",
      "complex         POS: ADJ        DEP: amod\n",
      "as              POS: ADP        DEP: prep\n",
      "Shakespearean   POS: ADJ        DEP: amod\n",
      "textual         POS: ADJ        DEP: amod\n",
      "studies         POS: NOUN       DEP: pobj\n",
      ";               POS: PUNCT      DEP: punct\n",
      "but             POS: CCONJ      DEP: cc\n",
      "Bowers          POS: NOUN       DEP: nsubj\n",
      "played          POS: VERB       DEP: conj\n",
      "an              POS: DET        DEP: det\n",
      "equally         POS: ADV        DEP: advmod\n",
      "important       POS: ADJ        DEP: amod\n",
      "role            POS: NOUN       DEP: dobj\n",
      "in              POS: ADP        DEP: prep\n",
      "other           POS: ADJ        DEP: amod\n",
      "areas           POS: NOUN       DEP: pobj\n",
      ".               POS: PUNCT      DEP: punct\n",
      "Editors         POS: NOUN       DEP: nsubj\n",
      "of              POS: ADP        DEP: prep\n",
      "nineteenth      POS: ADJ        DEP: amod\n",
      "-               POS: PUNCT      DEP: punct\n",
      "century         POS: NOUN       DEP: nmod\n",
      "American        POS: ADJ        DEP: amod\n",
      "authors         POS: NOUN       DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "for             POS: ADP        DEP: prep\n",
      "example         POS: NOUN       DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "would           POS: AUX        DEP: aux\n",
      "also            POS: ADV        DEP: advmod\n",
      "have            POS: VERB       DEP: ROOT\n",
      "to              POS: PART       DEP: aux\n",
      "call            POS: VERB       DEP: xcomp\n",
      "the             POS: DET        DEP: det\n",
      "recent          POS: ADJ        DEP: amod\n",
      "past            POS: NOUN       DEP: dobj\n",
      "“               POS: PUNCT      DEP: punct\n",
      "the             POS: DET        DEP: det\n",
      "age             POS: NOUN       DEP: dobj\n",
      "of              POS: ADP        DEP: prep\n",
      "Bowers          POS: PROPN      DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "”               POS: PUNCT      DEP: punct\n",
      "as              POS: SCONJ      DEP: mark\n",
      "would           POS: AUX        DEP: advcl\n",
      "the             POS: DET        DEP: det\n",
      "writers         POS: NOUN       DEP: nsubj\n",
      "of              POS: ADP        DEP: prep\n",
      "descriptive     POS: ADJ        DEP: amod\n",
      "bibliographies  POS: NOUN       DEP: pobj\n",
      "of              POS: ADP        DEP: prep\n",
      "authors         POS: NOUN       DEP: pobj\n",
      "and             POS: CCONJ      DEP: cc\n",
      "presses         POS: NOUN       DEP: conj\n",
      ".               POS: PUNCT      DEP: punct\n",
      "His             POS: PRON       DEP: poss\n",
      "ubiquity        POS: NOUN       DEP: nsubj\n",
      "in              POS: ADP        DEP: prep\n",
      "the             POS: DET        DEP: det\n",
      "broad           POS: ADJ        DEP: amod\n",
      "field           POS: NOUN       DEP: pobj\n",
      "of              POS: ADP        DEP: prep\n",
      "bibliographical POS: ADJ        DEP: amod\n",
      "and             POS: CCONJ      DEP: cc\n",
      "textual         POS: ADJ        DEP: conj\n",
      "study           POS: NOUN       DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "his             POS: PRON       DEP: poss\n",
      "seemingly       POS: ADV        DEP: advmod\n",
      "com-            POS: NOUN       DEP: amod\n",
      "plete           POS: ADJ        DEP: amod\n",
      "possession      POS: NOUN       DEP: appos\n",
      "of              POS: ADP        DEP: prep\n",
      "it              POS: PRON       DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "distinguished   POS: VERB       DEP: ROOT\n",
      "him             POS: PRON       DEP: dobj\n",
      "from            POS: ADP        DEP: prep\n",
      "his             POS: PRON       DEP: poss\n",
      "illustrious     POS: ADJ        DEP: amod\n",
      "predeces-       POS: NOUN       DEP: compound\n",
      "sors            POS: NOUN       DEP: pobj\n",
      "and             POS: CCONJ      DEP: cc\n",
      "made            POS: VERB       DEP: conj\n",
      "him             POS: PRON       DEP: nsubj\n",
      "the             POS: DET        DEP: det\n",
      "personification POS: NOUN       DEP: ccomp\n",
      "of              POS: ADP        DEP: prep\n",
      "bibliographical POS: ADJ        DEP: amod\n",
      "scholarship     POS: NOUN       DEP: pobj\n",
      "in              POS: ADP        DEP: prep\n",
      "his             POS: PRON       DEP: poss\n",
      "time            POS: NOUN       DEP: pobj\n",
      ".               POS: PUNCT      DEP: punct\n",
      "                POS: SPACE      DEP: dep\n",
      "When            POS: SCONJ      DEP: advmod\n",
      "in              POS: ADP        DEP: prep\n",
      "1969            POS: NUM        DEP: pobj\n",
      "Bowers          POS: NOUN       DEP: nsubjpass\n",
      "was             POS: AUX        DEP: auxpass\n",
      "awarded         POS: VERB       DEP: advcl\n",
      "the             POS: DET        DEP: det\n",
      "Gold            POS: PROPN      DEP: compound\n",
      "Medal           POS: PROPN      DEP: dobj\n",
      "of              POS: ADP        DEP: prep\n",
      "the             POS: DET        DEP: det\n",
      "Biblio-         POS: PROPN      DEP: nmod\n",
      "graphical       POS: ADJ        DEP: amod\n",
      "Society         POS: PROPN      DEP: pobj\n",
      "in              POS: ADP        DEP: prep\n",
      "London          POS: PROPN      DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "John            POS: PROPN      DEP: compound\n",
      "Carter          POS: PROPN      DEP: poss\n",
      "’s              POS: PART       DEP: case\n",
      "citation        POS: NOUN       DEP: nsubj\n",
      "referred        POS: VERB       DEP: ccomp\n",
      "to              POS: ADP        DEP: prep\n",
      "the             POS: DET        DEP: det\n",
      "Principles      POS: PROPN      DEP: pobj\n",
      "as              POS: ADP        DEP: prep\n",
      "“               POS: PUNCT      DEP: punct\n",
      "majestic        POS: ADJ        DEP: amod\n",
      ",               POS: PUNCT      DEP: punct\n",
      "”               POS: PUNCT      DEP: punct\n",
      "called          POS: VERB       DEP: ccomp\n",
      "Bowers          POS: PROPN      DEP: poss\n",
      "'s              POS: PART       DEP: case\n",
      "current         POS: ADJ        DEP: amod\n",
      "projects        POS: NOUN       DEP: dobj\n",
      "“               POS: PUNCT      DEP: punct\n",
      "formidable      POS: ADJ        DEP: amod\n",
      ",               POS: PUNCT      DEP: punct\n",
      "”               POS: PUNCT      DEP: punct\n",
      "said            POS: VERB       DEP: ROOT\n",
      "that            POS: SCONJ      DEP: mark\n",
      "he              POS: PRON       DEP: nsubj\n",
      "had             POS: AUX        DEP: aux\n",
      "“               POS: PUNCT      DEP: punct\n",
      "imposed         POS: VERB       DEP: ccomp\n",
      "critical        POS: ADJ        DEP: amod\n",
      "discipline      POS: NOUN       DEP: dobj\n",
      "”               POS: PUNCT      DEP: punct\n",
      "on              POS: ADP        DEP: prep\n",
      "the             POS: DET        DEP: det\n",
      "texts           POS: NOUN       DEP: pobj\n",
      "of              POS: ADP        DEP: prep\n",
      "several         POS: ADJ        DEP: amod\n",
      "authors         POS: NOUN       DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "described       POS: VERB       DEP: conj\n",
      "Studies         POS: PROPN      DEP: dobj\n",
      "in              POS: ADP        DEP: prep\n",
      "Bibliography    POS: PROPN      DEP: pobj\n",
      "as              POS: ADP        DEP: prep\n",
      "a               POS: DET        DEP: det\n",
      "“               POS: PUNCT      DEP: punct\n",
      "great           POS: ADJ        DEP: amod\n",
      "and             POS: CCONJ      DEP: cc\n",
      "continuing      POS: VERB       DEP: conj\n",
      "achievement     POS: NOUN       DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "”               POS: PUNCT      DEP: punct\n",
      "and             POS: CCONJ      DEP: cc\n",
      "included        POS: VERB       DEP: conj\n",
      "among           POS: ADP        DEP: prep\n",
      "his             POS: PRON       DEP: poss\n",
      "characteristics POS: NOUN       DEP: pobj\n",
      "‘               POS: PUNCT      DEP: punct\n",
      "uncompromising  POS: VERB       DEP: amod\n",
      "seriousness     POS: NOUN       DEP: dobj\n",
      "of              POS: ADP        DEP: prep\n",
      "purpose         POS: NOUN       DEP: pobj\n",
      "”               POS: PUNCT      DEP: punct\n",
      "and             POS: CCONJ      DEP: cc\n",
      "“               POS: PUNCT      DEP: punct\n",
      "professional    POS: ADJ        DEP: amod\n",
      "intensity       POS: NOUN       DEP: conj\n",
      ".               POS: PUNCT      DEP: punct\n",
      "”               POS: PUNCT      DEP: punct\n",
      "Bowers          POS: NOUN       DEP: nsubj\n",
      "was             POS: AUX        DEP: ROOT\n",
      "not             POS: PART       DEP: neg\n",
      "unaccustomed    POS: ADJ        DEP: acomp\n",
      "to              POS: ADP        DEP: prep\n",
      "such            POS: ADJ        DEP: amod\n",
      "encomia         POS: NOUN       DEP: pobj\n",
      ",               POS: PUNCT      DEP: punct\n",
      "but             POS: CCONJ      DEP: cc\n",
      "he              POS: PRON       DEP: nsubj\n",
      "had             POS: AUX        DEP: aux\n",
      "also            POS: ADV        DEP: advmod\n",
      "experienced     POS: VERB       DEP: conj\n",
      "his             POS: PRON       DEP: poss\n",
      "share           POS: NOUN       DEP: dobj\n",
      "of              POS: ADP        DEP: prep\n",
      "attacks         POS: NOUN       DEP: pobj\n",
      ":               POS: PUNCT      DEP: punct\n",
      "his             POS: PRON       DEP: poss\n",
      "scholarly       POS: ADJ        DEP: amod\n",
      "positions       POS: NOUN       DEP: nsubj\n",
      "were            POS: AUX        DEP: ccomp\n",
      "not             POS: PART       DEP: neg\n",
      "universally     POS: ADV        DEP: advmod\n",
      "popular         POS: ADJ        DEP: acomp\n",
      ",               POS: PUNCT      DEP: punct\n",
      "and             POS: CCONJ      DEP: cc\n",
      "he              POS: PRON       DEP: nsubj\n",
      "expressed       POS: VERB       DEP: conj\n",
      "them            POS: PRON       DEP: dobj\n",
      "with            POS: ADP        DEP: prep\n",
      "an              POS: DET        DEP: det\n",
      "aggressiveness  POS: NOUN       DEP: pobj\n",
      "that            POS: PRON       DEP: nsubj\n",
      "almost          POS: ADV        DEP: advmod\n",
      "seemed          POS: VERB       DEP: relcl\n",
      "calculated      POS: VERB       DEP: acomp\n",
      "to              POS: ADP        DEP: prep\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English tokenizer and pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(clean_text)\n",
    "\n",
    "# Print each token, its part of speech, and its syntactic dependency\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<15} POS: {token.pos_:<10} DEP: {token.dep_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c7ade-632d-4968-ac9b-83276e1d647b",
   "metadata": {},
   "source": [
    "Using spaCy, I was able to tokenize the text and view each token's part of speech and syntactic role. This gives great insight into how the sentence is structured, and it's a key step for downstream tasks like named entity recognition or sentiment analysis.\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
